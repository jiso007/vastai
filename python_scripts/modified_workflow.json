{
  "7": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "38",
        0
      ],
      "text": "low quality, lowres, bad hands, extra limbs, missing fingers, poorly drawn face, bad anatomy, blurred, jpeg artifacts, deformed, ugly, bad proportions, disfigured, watermark, text, logo, signature, unrealistic eyes, cross-eyed, lopsided, bad lighting, harsh shadows, flat shading, unshapely body, pixelated, duplicate limbs, bad perspective, morphed, distorted, glitch, malformed hands, distorted fingers, noisy background, overly saturated, unnatural colors, lens distortion, grainy, low detail,"
    }
  },
  "39": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    }
  },
  "38": {
    "class_type": "CLIPLoader",
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    }
  },
  "55": {
    "class_type": "ModelSamplingSD3",
    "inputs": {
      "model": [
        "82",
        0
      ],
      "shift": 8
    }
  },
  "54": {
    "class_type": "ModelSamplingSD3",
    "inputs": {
      "model": [
        "80",
        0
      ],
      "shift": 8.000000000000002
    }
  },
  "37": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    }
  },
  "56": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    }
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": [
        "58",
        0
      ],
      "vae": [
        "39",
        0
      ]
    }
  },
  "91": {
    "class_type": "RIFE VFI",
    "inputs": {
      "frames": [
        "8",
        0
      ],
      "ckpt_name": "rife47.pth",
      "clear_cache_after_n_frames": 50,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1
    }
  },
  "61": {
    "class_type": "SaveVideo",
    "inputs": {
      "video": [
        "60",
        0
      ],
      "filename_prefix": "video/ComfyUI",
      "format": "auto",
      "codec": "h264"
    }
  },
  "57": {
    "class_type": "KSamplerAdvanced",
    "inputs": {
      "model": [
        "54",
        0
      ],
      "positive": [
        "63",
        0
      ],
      "negative": [
        "63",
        1
      ],
      "latent_image": [
        "63",
        2
      ],
      "add_noise": "enable",
      "noise_seed": 325439875298244,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": 0,
      "end_at_step": 2,
      "return_with_leftover_noise": "enable"
    }
  },
  "82": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "56",
        0
      ],
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
      "strength_model": 1
    }
  },
  "60": {
    "class_type": "CreateVideo",
    "inputs": {
      "images": [
        "91",
        0
      ],
      "fps": 16
    }
  },
  "63": {
    "class_type": "WanImageToVideo",
    "inputs": {
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "start_image": [
        "62",
        0
      ],
      "width": 848,
      "height": 480,
      "length": 65,
      "batch_size": 1
    }
  },
  "58": {
    "class_type": "KSamplerAdvanced",
    "inputs": {
      "model": [
        "55",
        0
      ],
      "positive": [
        "63",
        0
      ],
      "negative": [
        "63",
        1
      ],
      "latent_image": [
        "57",
        0
      ],
      "add_noise": "disable",
      "noise_seed": 0,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": 2,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable"
    }
  },
  "80": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "37",
        0
      ],
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
      "strength_model": 1.0000000000000002
    }
  },
  "6": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "38",
        0
      ],
      "text": "im a potato"
    }
  },
  "62": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "test-image.png",
      "upload": "image"
    }
  }
}
